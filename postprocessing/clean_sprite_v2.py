"""
Script intended to clean a sprite generated by our model. It will downsample, reduce color palette and finally remove magenta background.
Pixelation and palet reduction is adapted from https://github.com/Astropulse/pixeldetector/blob/main/pixeldetector.py
"""

import math
from collections import Counter, deque
import os
from PIL import Image
import numpy as np
import scipy
from itertools import product


def _kCentroid(image: Image, width: int, height: int, centroids: int):
    image = image.convert("RGB")

    # Create an empty array for the downscaled image
    downscaled = np.zeros((height, width, 3), dtype=np.uint8)

    # Calculate the scaling factors
    wFactor = image.width / width
    hFactor = image.height / height

    # Iterate over each tile in the downscaled image
    for x, y in product(range(width), range(height)):
        # Crop the tile from the original image
        tile = image.crop(
            (x * wFactor, y * hFactor, (x * wFactor) + wFactor, (y * hFactor) + hFactor)
        )

        # Quantize the colors of the tile using k-means clustering
        tile = tile.quantize(colors=centroids, method=1, kmeans=centroids).convert(
            "RGB"
        )

        # Get the color counts and find the most common color
        color_counts = tile.getcolors()
        most_common_color = max(color_counts, key=lambda x: x[0])[1]

        # Assign the most common color to the corresponding pixel in the downscaled image
        downscaled[y, x, :] = most_common_color

    return Image.fromarray(downscaled)


def _pixelate(image: Image):
    # Convert the image to a NumPy array
    npim = np.array(image)[..., :3]

    # Compute horizontal differences between pixels
    hdiff = np.sqrt(np.sum((npim[:, :-1, :] - npim[:, 1:, :]) ** 2, axis=2))
    hsum = np.sum(hdiff, 0)

    # Compute vertical differences between pixels
    vdiff = np.sqrt(np.sum((npim[:-1, :, :] - npim[1:, :, :]) ** 2, axis=2))
    vsum = np.sum(vdiff, 1)

    # Find peaks in the horizontal and vertical sums
    hpeaks, _ = scipy.signal.find_peaks(hsum, distance=1, height=0.0)
    vpeaks, _ = scipy.signal.find_peaks(vsum, distance=1, height=0.0)

    # Compute spacing between the peaks
    hspacing = np.diff(hpeaks)
    vspacing = np.diff(vpeaks)

    # Resize input image using kCentroid with the calculated horizontal and vertical factors
    return _kCentroid(
        image,
        round(image.width / np.median(hspacing)),
        round(image.height / np.median(vspacing)),
        2,
    )


def _determine_best_k(image: Image, max_k: int):
    # Convert the image to RGB mode
    image = image.convert("RGB")

    # Prepare arrays for distortion calculation
    pixels = np.array(image)
    pixel_indices = np.reshape(pixels, (-1, 3))

    # Calculate distortion for different values of k
    distortions = []
    for k in range(1, max_k + 1):
        quantized_image = image.quantize(colors=k, method=0, kmeans=k, dither=0)
        centroids = np.array(quantized_image.getpalette()[: k * 3]).reshape(-1, 3)

        # Calculate distortions
        distances = np.linalg.norm(pixel_indices[:, np.newaxis] - centroids, axis=2)
        min_distances = np.min(distances, axis=1)
        distortions.append(np.sum(min_distances**2))

    # Calculate the rate of change of distortions
    rate_of_change = np.diff(distortions) / np.array(distortions[:-1])

    # Find the elbow point (best k value)
    if len(rate_of_change) == 0:
        best_k = 2
    else:
        elbow_index = np.argmax(rate_of_change) + 1
        best_k = elbow_index + 2

    return best_k


def _reduce_palette(image: Image, max_colors: int):
    best_k = _determine_best_k(image, max_colors)
    return image.quantize(colors=best_k, method=1, kmeans=best_k, dither=0).convert(
        "RGB"
    )


def _detect_background_color(arr: np.ndarray):
    """Pick the most likely background color using corners + sparse grid sample."""
    H, W, _ = arr.shape
    samples = []

    # corners & mid-edges
    coords = [
        (0, 0),
        (W - 1, 0),
        (0, H - 1),
        (W - 1, H - 1),
        (W // 2, 0),
        (0, H // 2),
        (W - 1, H // 2),
        (W // 2, H - 1),
    ]
    for x, y in coords:
        samples.append(tuple(int(v) for v in arr[y, x]))

    # sparse grid (20x20 approx)
    step_y = max(1, H // 20)
    step_x = max(1, W // 20)
    for y in range(0, H, step_y):
        for x in range(0, W, step_x):
            samples.append(tuple(int(v) for v in arr[y, x]))

    return Counter(samples).most_common(1)[0][0]  # (r,g,b)


def _color_distance_map(arr: np.ndarray, bg: tuple):
    """Euclidean distance in RGB to background color."""
    bg_vec = np.array(bg, dtype=np.float32)[None, None, :]
    arrf = arr.astype(np.float32)
    diff = arrf - bg_vec
    dist = np.sqrt(np.sum(diff * diff, axis=2))
    return dist


def _crop_with_margin(box, W, H, margin):
    xmin, ymin, xmax, ymax = box
    return (
        max(0, xmin - margin),
        max(0, ymin - margin),
        min(W - 1, xmax + margin),
        min(H - 1, ymax + margin),
    )


def _largest_component_mask(mask: np.ndarray):
    """
    Return (comp_mask, bbox, count) for the largest 4-neighborhood connected component in `mask`.
    comp_mask has the same shape as mask (bool).
    bbox = (xmin,ymin,xmax,ymax)
    """
    H, W = mask.shape
    visited = np.zeros_like(mask, dtype=bool)
    best_coords = None
    best_count = 0
    best_bbox = None

    for y in range(H):
        if not mask[y].any():
            continue
        for x in range(W):
            if mask[y, x] and not visited[y, x]:
                q = deque([(x, y)])
                visited[y, x] = True
                xs, ys = [], []
                count = 0
                while q:
                    cx, cy = q.popleft()
                    xs.append(cx)
                    ys.append(cy)
                    count += 1
                    # neighbors (4-neighborhood)
                    if cx + 1 < W and mask[cy, cx + 1] and not visited[cy, cx + 1]:
                        visited[cy, cx + 1] = True
                        q.append((cx + 1, cy))
                    if cx - 1 >= 0 and mask[cy, cx - 1] and not visited[cy, cx - 1]:
                        visited[cy, cx - 1] = True
                        q.append((cx - 1, cy))
                    if cy + 1 < H and mask[cy + 1, cx] and not visited[cy + 1, cx]:
                        visited[cy + 1, cx] = True
                        q.append((cx, cy + 1))
                    if cy - 1 >= 0 and mask[cy - 1, cx] and not visited[cy - 1, cx]:
                        visited[cy - 1, cx] = True
                        q.append((cx, cy - 1))
                if count > best_count:
                    best_count = count
                    best_coords = (xs, ys)
                    best_bbox = (min(xs), min(ys), max(xs), max(ys))

    if best_coords is None:
        return None, None, 0

    xs, ys = best_coords
    comp_mask = np.zeros_like(mask, dtype=bool)
    comp_mask[np.array(ys), np.array(xs)] = True
    return comp_mask, best_bbox, best_count


def _make_alpha_from_distance(dist: np.ndarray, tol: float, feather: float):
    """
    Turn color distance into alpha. Pixels near the bg color get alpha 0,
    pixels clearly different get alpha 255. `feather` softens the edge in distance units.
    """
    if feather <= 0:
        return (dist > tol).astype(np.uint8) * 255
    # ramp from (tol - feather) -> 0 up to tol -> 255
    a = (dist - (tol - feather)) / max(1e-6, feather)
    a = np.clip(a, 0.0, 1.0)
    return (a * 255).astype(np.uint8)


def _erode_mask(mask: np.ndarray, iterations: int = 1):
    """
    Simple binary erosion (shrink foreground by N pixels).
    Uses 4-neighborhood (cross kernel).
    """
    result = mask.copy()
    for _ in range(iterations):
        H, W = result.shape
        eroded = np.zeros_like(result, dtype=bool)
        for y in range(H):
            for x in range(W):
                if result[y, x]:
                    # Check 4-neighbors
                    has_all_neighbors = True
                    if x == 0 or not result[y, x - 1]:
                        has_all_neighbors = False
                    if x == W - 1 or not result[y, x + 1]:
                        has_all_neighbors = False
                    if y == 0 or not result[y - 1, x]:
                        has_all_neighbors = False
                    if y == H - 1 or not result[y + 1, x]:
                        has_all_neighbors = False
                    if has_all_neighbors:
                        eroded[y, x] = True
        result = eroded
    return result


def _remove_background(
    image: Image.Image,
    bg_color=None,  # specific background color (r,g,b) or None to auto-detect
    tol=50,  # color distance tolerance vs. background
    margin=5,  # extra pixels around bbox in the output crop
    feather=0,  # softness of alpha edge (in color-distance units)
    expand_mask=0,  # erode the mask by N pixels to remove edge artifacts
):

    W, H = image.size
    rgb = np.array(image)

    # 1) Background color + distance map
    if bg_color is not None:
        bg = tuple(bg_color)
    else:
        bg = _detect_background_color(rgb)
    dist = _color_distance_map(rgb, bg)

    if tol is None:
        # For known bg colors (especially magenta), use higher tolerance
        if bg_color is not None:
            tol = 50.0  # more aggressive for known backgrounds
        else:
            tol = float(
                max(25, 0.05 * math.sqrt(255**2 * 3))
            )  # â‰ˆ5% of max RGB distance

    # 2) Foreground mask
    fg_mask = dist > tol

    # 3) Largest connected component (the sprite)
    comp_mask_full, bbox, count = _largest_component_mask(fg_mask)
    if comp_mask_full is None:
        raise ValueError(
            "No sprite-like component found. Try lowering `tol` or thresholds."
        )

    # 4) Crop with margin
    xmin, ymin, xmax, ymax = bbox
    xmin2, ymin2, xmax2, ymax2 = _crop_with_margin(
        (xmin, ymin, xmax, ymax), W, H, margin
    )

    # slice everything to the crop
    rgb_crop = rgb[ymin2 : ymax2 + 1, xmin2 : xmax2 + 1]
    dist_crop = dist[ymin2 : ymax2 + 1, xmin2 : xmax2 + 1]
    mask_crop = fg_mask[ymin2 : ymax2 + 1, xmin2 : xmax2 + 1]

    # 5) Within the crop, re-isolate the largest component to be safe
    comp_mask_crop, _, _ = _largest_component_mask(mask_crop)
    if comp_mask_crop is None:
        # fallback: use the original fg mask within crop
        comp_mask_crop = mask_crop

    # 5b) Optionally erode the mask to remove edge artifacts
    if expand_mask > 0:
        comp_mask_crop = _erode_mask(comp_mask_crop, iterations=expand_mask)

    # 6) Build alpha: feathered by distance, but only keep the chosen component
    alpha_soft = _make_alpha_from_distance(dist_crop, tol=tol, feather=feather)
    alpha = alpha_soft * comp_mask_crop.astype(np.uint8)

    # 7) Compose RGBA with transparent background
    rgba = np.dstack([rgb_crop, alpha]).astype(np.uint8)
    out_img = Image.fromarray(rgba)

    return out_img


def clean_image(
    input_path: str,
    output_path: str,
    max_colors: int = 16,
    tol: float = 50,
    margin: int = 5,
    expand_mask: int = 0,
):
    """
    Pixelate, reduce color palette and remove background.

    Args:
        input_path: Path to input image
        output_path: Path to save output image (default: "output.png")
        max_colors: Max colors for computation (default: 16)
        tol: Color distance tolerance vs. background (default: 50)
        margin: Extra pixels around bbox in the output crop (default: 5)
        expand_mask: Shrink the foreground mask inward by this many pixels to remove edge artifacts (default: 0)

    Returns:
        tuple: (output_image) or None if file doesn't exist
    """
    if not os.path.isfile(input_path):
        print(f"Error: File not found: {input_path}")
        return None

    image = Image.open(input_path).convert("RGB")

    # Pixelate the image
    pixelated = _pixelate(image)

    # Reduce the color palette
    reduced_palette = _reduce_palette(pixelated, max_colors)

    # Remove the magenta background
    cleaned = _remove_background(
        reduced_palette, tol=tol, margin=margin, expand_mask=expand_mask
    )

    # upscale the image to the original size with nearest neighbor
    output = cleaned.resize(image.size, Image.NEAREST)
    output.save(output_path)
    print(f"Upscaled image saved to {output_path}")

    return output


if __name__ == "__main__":
    input_dir = "output_dq"
    output_dir = "output_dq_cleaned_v2"
    max_colors = 16
    tol = 70
    margin = 5
    expand_mask = 1
    for file in os.listdir(input_dir):
        if file.endswith(".png"):
            input_image_path = os.path.join(input_dir, file)
            output_image_path = os.path.join(output_dir, file)
            clean_image(
                input_image_path,
                output_image_path,
                max_colors,
                tol,
                margin,
                expand_mask,
            )
